{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T14:01:22.407169Z",
     "start_time": "2024-07-08T14:01:22.036144Z"
    }
   },
   "source": "import pandas as pd",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T14:21:18.684342Z",
     "start_time": "2024-07-08T14:20:46.569123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file to examine its structure\n",
    "file_path = 'Book3.csv'\n",
    "book3_df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract stock symbols from the DataFrame\n",
    "stock_symbols = book3_df.columns\n",
    "\n",
    "# Function to fetch historical data\n",
    "def fetch_historical_data(symbol, period=\"1y\"):\n",
    "    ticker = yf.Ticker(symbol+\".NS\")\n",
    "    hist = ticker.history(period=period)\n",
    "    return hist\n",
    "\n",
    "# Dictionary to store historical data\n",
    "historical_data = {}\n",
    "\n",
    "exception_list = []\n",
    "\n",
    "# Fetch historical data for each stock symbol\n",
    "for symbol in stock_symbols:\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol+\".NS\")\n",
    "        hist = ticker.history(period=\"1y\")\n",
    "    except Exception as e:\n",
    "        exception_list.append(symbol)\n",
    "        print(f\"Could not fetch data for {symbol}: {e}\")\n",
    "\n",
    "# Convert outstanding shares data to long format for merging\n",
    "outstanding_shares_df = book3_df.melt(id_vars=['Unnamed: 0.2'], var_name='Symbol', value_name='Outstanding_Shares')\n",
    "outstanding_shares_df.rename(columns={'Unnamed: 0.2': 'Year'}, inplace=True)\n",
    "\n",
    "# Create a list to store processed data\n",
    "processed_data = []\n",
    "\n",
    "# Process each stock symbol\n",
    "for symbol in stock_symbols:\n",
    "    if symbol in historical_data:\n",
    "        hist_df = historical_data[symbol]\n",
    "        hist_df['Year'] = hist_df.index.year\n",
    "        outstanding_shares = outstanding_shares_df[outstanding_shares_df['Symbol'] == symbol]\n",
    "\n",
    "        # Merge historical data with outstanding shares data\n",
    "        merged_df = hist_df.reset_index().merge(outstanding_shares, on='Year', how='left')\n",
    "        merged_df['Turnover'] = merged_df['Volume'] / merged_df['Outstanding_Shares']\n",
    "        \n",
    "        # Append to processed data list\n",
    "        processed_data.append(merged_df)\n",
    "\n",
    "# Concatenate all processed data\n",
    "final_df = pd.concat(processed_data, ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "final_df.to_csv('/mnt/data/final_turnover_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "final_df.head()\n"
   ],
   "id": "1ad3a6ff582ca0eb",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:17:10.446766Z",
     "start_time": "2024-07-08T16:16:27.678805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the provided CSV file\n",
    "file_path = 'Book3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the date range to end at the last day of 2023\n",
    "end_date = datetime(2024, 1, 1)\n",
    "start_date = end_date - pd.DateOffset(years=10)\n",
    "\n",
    "# Initialize a list to keep track of any errors and a list to store the merged data\n",
    "errors = []\n",
    "merged_data_list = []\n",
    "\n",
    "# Process each stock in the data (excluding the 'YEAR' column)\n",
    "for ticker in data.columns[1:]:\n",
    "    try:\n",
    "        # Fetch historical data for the stock\n",
    "        stock_data = yf.download(f\"{ticker}.NS\", start=start_date, end=end_date)\n",
    "        \n",
    "        # Round the stock data to one decimal place\n",
    "        stock_data = stock_data.round(1)\n",
    "        \n",
    "        # Add additional columns to the stock data\n",
    "        stock_data['Date'] = stock_data.index\n",
    "        stock_data['Symbol'] = ticker\n",
    "        stock_data['Year'] = stock_data.index.year\n",
    "        \n",
    "        # Drop the High, Low, and Close columns\n",
    "        stock_data.drop(columns=['High', 'Low', 'Open', 'Close'], inplace=True)\n",
    "        \n",
    "        # Merge the outstanding shares data with the stock data for each year\n",
    "        outstanding_shares_data = data[['YEAR', ticker]]\n",
    "        outstanding_shares_data.columns = ['Year', 'Outstanding_Shares']\n",
    "        \n",
    "        # Merge the data based on the Year column while retaining the index\n",
    "        merged_data = stock_data.merge(outstanding_shares_data, on='Year', how='left')\n",
    "        \n",
    "        # Append the merged data to the list\n",
    "        merged_data_list.append(merged_data)\n",
    "    except Exception as e:\n",
    "        errors.append((ticker, str(e)))\n",
    "\n",
    "# Combine all the merged data into a single DataFrame\n",
    "combined_data = pd.concat(merged_data_list)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_data.to_csv('combined_stock_data.csv', index=False)\n",
    "\n",
    "# Print errors if any occurred\n",
    "print(errors)\n"
   ],
   "id": "1efe01238be1d0d4",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:39:47.298837Z",
     "start_time": "2024-07-14T11:39:46.771414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('combined_stock_data.csv')\n",
    "\n",
    "data.groupby('Symbol')['Date'].count()"
   ],
   "id": "ea485a2855dc62b0",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:26:57.213656Z",
     "start_time": "2024-07-08T16:26:57.075249Z"
    }
   },
   "cell_type": "code",
   "source": "stock_data = yf.download(\"SAFARI.NS\", start=start_date, end=end_date)",
   "id": "e2e213864a9a5a4f",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:42:01.470520Z",
     "start_time": "2024-07-14T11:42:01.345374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Count the occurrences of each symbol\n",
    "symbol_counts = data.groupby('Symbol')['Date'].count()\n",
    "\n",
    "# Step 2: Filter symbols with at least 2465 occurrences\n",
    "valid_symbols = symbol_counts[symbol_counts >= 2465].index\n",
    "\n",
    "# Step 3: Filter the original DataFrame to include only valid symbols\n",
    "filtered_data = data[data['Symbol'].isin(valid_symbols)]"
   ],
   "id": "af3a025416d135ba",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:43:16.465985Z",
     "start_time": "2024-07-14T11:43:14.622308Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data.to_csv('final_data.csv')",
   "id": "e79994e0531b0159",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b1adc33e5e300ffa",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
