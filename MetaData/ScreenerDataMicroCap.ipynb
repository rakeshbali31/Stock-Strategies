{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19fc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d073ffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract data from page 1. Error: list index out of range\n",
      "Failed to extract data from page 2. Error: list index out of range\n",
      "Failed to extract data from page 3. Error: list index out of range\n",
      "Failed to extract data from page 4. Error: list index out of range\n",
      "Failed to extract data from page 5. Error: list index out of range\n",
      "Failed to extract data from page 6. Error: list index out of range\n",
      "Failed to extract data from page 7. Error: list index out of range\n",
      "Failed to extract data from page 8. Error: list index out of range\n",
      "Failed to extract data from page 9. Error: list index out of range\n",
      "Failed to extract data from page 10. Error: list index out of range\n",
      "Failed to extract data from page 11. Error: list index out of range\n",
      "Failed to extract data from page 12. Error: list index out of range\n",
      "Failed to extract data from page 13. Error: list index out of range\n",
      "Failed to extract data from page 14. Error: list index out of range\n",
      "Failed to extract data from page 15. Error: list index out of range\n",
      "Failed to extract data from page 16. Error: list index out of range\n",
      "Failed to extract data from page 17. Error: list index out of range\n",
      "Failed to extract data from page 18. Error: list index out of range\n",
      "Failed to extract data from page 19. Error: list index out of range\n",
      "Failed to extract data from page 20. Error: list index out of range\n",
      "Failed to extract data from page 21. Error: list index out of range\n",
      "Failed to extract data from page 22. Error: list index out of range\n",
      "Failed to extract data from page 23. Error: list index out of range\n",
      "Failed to extract data from page 24. Error: list index out of range\n",
      "Failed to extract data from page 25. Error: list index out of range\n",
      "Failed to extract data from page 26. Error: list index out of range\n",
      "Failed to extract data from page 27. Error: list index out of range\n",
      "Failed to extract data from page 28. Error: list index out of range\n",
      "Failed to extract data from page 29. Error: list index out of range\n",
      "Failed to extract data from page 30. Error: list index out of range\n",
      "Failed to extract data from page 31. Error: list index out of range\n",
      "Failed to extract data from page 32. Error: list index out of range\n",
      "Failed to extract data from page 33. Error: list index out of range\n",
      "Failed to extract data from page 34. Error: list index out of range\n",
      "Failed to extract data from page 35. Error: list index out of range\n",
      "Failed to extract data from page 36. Error: list index out of range\n",
      "Failed to extract data from page 37. Error: list index out of range\n",
      "Failed to extract data from page 38. Error: list index out of range\n",
      "Failed to extract data from page 39. Error: list index out of range\n",
      "Failed to extract data from page 40. Error: list index out of range\n",
      "Failed to extract data from page 41. Error: list index out of range\n",
      "Failed to extract data from page 42. Error: list index out of range\n",
      "All data extracted and stored in screener_data_micro.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to extract and store data from a page\n",
    "def extract_data(url, headers, writer):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', class_='data-table')\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skipping header row\n",
    "            cols = row.find_all('td')\n",
    "            symbol = str(cols[1].find('a')).split('/')[2]\n",
    "            data = [col.text.strip() for col in cols]\n",
    "            data.append(symbol)\n",
    "            writer.writerow(data)\n",
    "\n",
    "# URL of the website\n",
    "base_url = 'https://www.screener.in/screens/1599632/screenerdatamicro/?page='\n",
    "\n",
    "# Session ID and CSRF token obtained from somewhere (e.g., through authentication)\n",
    "session_id = 'gxja81spl0xn0hggiwu4g5kxmhnbv9mz'\n",
    "csrf_token = '8uCAl5uBfrOlzD295ykL6XYQ6BNEPwQU'\n",
    "\n",
    "# Construct headers with session ID and CSRF token\n",
    "headers = {\n",
    "    'Cookie': f'sessionid={session_id}',  # Assuming the session ID is passed via cookie\n",
    "    'X-CSRFToken': csrf_token  # Assuming the CSRF token is passed in a header\n",
    "}\n",
    "\n",
    "# CSV file to store the data\n",
    "csv_filename = 'screener_data_micro.csv'\n",
    "fieldnames = ['S.No.', 'Name', 'CMP Rs.', 'P/E', 'Mar Cap Rs.Cr.', 'Qtr Sales Var %', 'Qtr Profit Var %', \n",
    "              'QoQ Sales %', 'QoQ Profits %', 'Prom. Hold. %', 'DII Hold %', 'FII Hold %', 'Exp Qtr Sales Var %',\n",
    "              'RSI Rs.', 'MACD Signal Rs.', 'Change in Prom Hold %', 'ROCE', 'SYMBOL']\n",
    "\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "    for page_num in range(1, 43):  # Iterate over pages 1 to 30\n",
    "        url = base_url + str(page_num) + '&limit=10'\n",
    "        try:\n",
    "            extract_data(url, headers, writer)\n",
    "            print(f\"Data from page {page_num} extracted and stored.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from page {page_num}. Error: {e}\")\n",
    "\n",
    "print(\"All data extracted and stored in\", csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd0ba5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
