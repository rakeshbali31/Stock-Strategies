{
 "cells": [
  {
   "cell_type": "code",
   "id": "060e17ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T08:52:31.859985Z",
     "start_time": "2024-07-12T08:52:31.684011Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from bsedata.bse import BSE"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b87d773b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T08:52:37.581873Z",
     "start_time": "2024-07-12T08:52:31.860789Z"
    }
   },
   "source": [
    "bse = BSE(update_codes = True)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:58:28.133858Z",
     "start_time": "2024-07-12T09:58:20.741281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_companies(keyword, pages=10):\n",
    "    # Base URL and headers with session ID and CSRF token\n",
    "    base_url = \"https://www.screener.in/full-text-search/\"\n",
    "    session_id = 'jbj4ibouxarr9trfu2zndv9ns07n8qnl'\n",
    "    csrf_token = 'RBIDkDj3gz0wIf3EH0JGPgGdYX9tLizS'\n",
    "    \n",
    "    headers = {\n",
    "        'Cookie': f'sessionid={session_id}',\n",
    "        'X-CSRFToken': csrf_token\n",
    "    }\n",
    "    \n",
    "    companies = []\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{base_url}?q={keyword}&page={page}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve page {page}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all blocks containing company information\n",
    "        company_blocks = soup.find_all('div', class_='margin-top-20 margin-bottom-36')\n",
    "\n",
    "        # Loop through each block and extract information\n",
    "        for block in company_blocks:\n",
    "            # Extract company name\n",
    "            company_name_span = block.find('span', class_='hover-link ink-900')\n",
    "            company_name = company_name_span.get_text(strip=True)\n",
    "    \n",
    "            # Extract company code from the href attribute of the <a> tag\n",
    "            company_code = company_name_span.find_parent('a')['href'].split('/')[2]\n",
    "    \n",
    "            # Extract PDF link\n",
    "            pdf_link = block.find('div', class_='font-size-17 font-weight-500').find('a')['href']\n",
    "    \n",
    "            # Extract comment text\n",
    "            comment_div = block.find('div', class_='ink-700 font-size-16')\n",
    "            comment_text = comment_div.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "            # Append to the list\n",
    "            companies.append({\n",
    "                'Company Name': company_name,\n",
    "                'Company Code': company_code,\n",
    "                'Comment': comment_text,\n",
    "                'PDF Link': pdf_link\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(companies)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "keyword = \"Artificial Intelligence\"\n",
    "df = scrape_companies(keyword, pages=10)"
   ],
   "id": "b7afbcec162858c4",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a62396c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:58:05.664629Z",
     "start_time": "2024-07-12T09:58:05.659039Z"
    }
   },
   "source": "df",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b59b701c",
   "metadata": {},
   "source": [
    "## PLOT ALL TIME HIGH STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b760773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T19:26:49.205181Z",
     "start_time": "2024-06-24T19:26:03.344067Z"
    }
   },
   "source": [
    "# Define functions to download stock data, calculate indicators, plot data, and process stocks\n",
    "def download_stock_data(symbol):\n",
    "    return yf.download(symbol + \".BO\", start=pd.to_datetime('today') - pd.DateOffset(365),\n",
    "                       end=pd.to_datetime('today') + pd.DateOffset(1), progress=False)\n",
    "\n",
    "def calculate_technical_indicators(data):\n",
    "    data['5DMA'] = data['Close'].rolling(window=5).mean()\n",
    "    data['20DMA'] = data['Close'].rolling(window=20).mean()\n",
    "    data['50DMA'] = data['Close'].rolling(window=50).mean()\n",
    "    data['100DMA'] = data['Close'].rolling(window=100).mean()\n",
    "    data['diff'] = data['Close'] - data['Open']\n",
    "    data['color'] = data['diff'].apply(lambda x: 'green' if x >= 0 else 'red')\n",
    "    return data\n",
    "\n",
    "def plot_stock_data(symbol, data, comment, pdf_link):\n",
    "    # Prepare plot data\n",
    "    plot_data = data[data.index > (pd.to_datetime('today') - pd.DateOffset(days=180))]\n",
    "\n",
    "    # Setup subplot layout\n",
    "    figure = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Plot candlestick chart\n",
    "    figure.add_trace(go.Candlestick(x=plot_data.index,\n",
    "                                    open=plot_data['Open'],\n",
    "                                    high=plot_data['High'],\n",
    "                                    low=plot_data['Low'],\n",
    "                                    close=plot_data['Close'],\n",
    "                                    name='Price'))\n",
    "\n",
    "    # Adjust Y-axis and layout for stock prices\n",
    "    figure.update_yaxes(range=[plot_data['Close'].min()*0.9, plot_data['Close'].max()*1.05])\n",
    "    figure.update_xaxes(rangebreaks=[dict(bounds=['sat', 'mon'])], row=1, col=1)  # hide weekends\n",
    "    figure.update_layout(title={'text': symbol, 'x': 0.5}, xaxis_rangeslider_visible=False)\n",
    "\n",
    "    # Plot moving averages and volume\n",
    "    for ma, color in zip(['5DMA', '20DMA', '50DMA', '100DMA'], ['yellow', 'blue', 'orange', 'green']):\n",
    "        figure.add_trace(go.Scatter(x=plot_data.index, y=plot_data[ma], marker_color=color, name=f'{ma}'))\n",
    "    figure.add_trace(go.Bar(x=plot_data.index, y=plot_data['Volume'], name='Volume',\n",
    "                            marker={'color': plot_data['color']}), secondary_y=True)\n",
    "    \n",
    "    # Hide the secondary Y-axis (volume)\n",
    "    figure.update_yaxes(range=[0, plot_data['Volume'].max()*5], secondary_y=True)\n",
    "    figure.update_yaxes(visible=False, secondary_y=True)\n",
    "    \n",
    "    # Add company comment and PDF link below the chart using annotations\n",
    "    figure.update_layout(\n",
    "        annotations=[\n",
    "            dict(\n",
    "                text=f\"<b>Comment:</b> {comment}<br><b>PDF Link:</b> <a href='{pdf_link}' target='_blank'>{pdf_link}</a>\",\n",
    "                xref=\"paper\", yref=\"paper\", x=0, y=-0.2, showarrow=False, align='left',\n",
    "                xanchor='left', yanchor='top'\n",
    "            )\n",
    "        ],\n",
    "        margin={'b': 200}  # Extend the bottom margin to make room for the annotation\n",
    "    )\n",
    "\n",
    "    return figure\n",
    "\n",
    "def process_stocks(all_symbols, comments, pdf_links):\n",
    "    num_processed = 0\n",
    "    file_count = 1\n",
    "    while num_processed < len(all_symbols):\n",
    "        figure_html = open(f'keyword_stocks_{file_count}.html', 'w')\n",
    "        for idx, symbol in enumerate(all_symbols[num_processed:num_processed+100]):\n",
    "            try:\n",
    "                data = download_stock_data(symbol)\n",
    "                data = calculate_technical_indicators(data)\n",
    "                comment = comments[num_processed + idx]\n",
    "                pdf_link = pdf_links[num_processed + idx]\n",
    "                figure = plot_stock_data(symbol, data, comment, pdf_link)\n",
    "                figure_html.write(figure.to_html(full_html=False))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing symbol {symbol}: {e}\")\n",
    "        figure_html.close()\n",
    "        num_processed += 100\n",
    "        file_count += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbols = df['Company Code'].values\n",
    "    comments = df['Comment'].values\n",
    "    pdf_links = df['PDF Link'].values\n",
    "    process_stocks(symbols, comments, pdf_links)\n",
    "    print('Execution Completed!!!!')"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b7ddae9085afb896",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
